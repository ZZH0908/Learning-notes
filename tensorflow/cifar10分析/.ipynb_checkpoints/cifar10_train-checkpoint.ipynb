{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "# 数据集路径\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "# 最大迭代步数\n",
    "tf.app.flags.DEFINE_integer('max_steps', 100000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "#多久记录一次log\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        # 返回全局步数\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "        # Get images and labels for CIFAR-10.\n",
    "        # Force input pipeline to CPU:0 to avoid operations sometimes ending up on\n",
    "        # GPU and resulting in a slow down.\n",
    "        with tf.device('/cpu:0'):\n",
    "            images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "        # Build a Graph that computes the logits predictions from the\n",
    "        # inference model.\n",
    "        logits = cifar10.inference(images)\n",
    "\n",
    "        # Calculate loss.\n",
    "        loss = cifar10.loss(logits, labels)\n",
    "\n",
    "        # Build a Graph that trains the model with one batch of examples and\n",
    "        # updates the model parameters.\n",
    "        train_op = cifar10.train(loss, global_step)\n",
    "        \n",
    "        # tf.train.SessionRunHook()是一个类；用来定义Hooks\n",
    "        # Hooks是在模型训练/测试过程中的工具、是继承类的关系\n",
    "        class _LoggerHook(tf.train.SessionRunHook):\n",
    "            \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "            def begin(self):\n",
    "               \"\"\"\"Called once before using the session.\n",
    "                   When called, the default graph is the one that will be launched in \n",
    "                   the session. The hook can modify the graph by adding new operations to it. \n",
    "                   After the begin() call the graph will be finalized and the other callbacks \n",
    "                   can not modify the graph anymore. Second call of begin() on the same graph, \n",
    "                   should not change the graph.\"\"\"\n",
    "                \"\"\"再创建会话之前调用调用begin()时，default graph会被创建，\n",
    "                   可在此处向default graph增加新op,begin()调用后，default graph不能再被修改\n",
    "                \"\"\"\n",
    "                self._step = -1\n",
    "                self._start_time = time.time()\n",
    "\n",
    "            def before_run(self, run_context):\n",
    "                self._step += 1\n",
    "            return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "            def after_run(self, run_context, run_values):\n",
    "                if self._step % FLAGS.log_frequency == 0:\n",
    "                    current_time = time.time()\n",
    "                    duration = current_time - self._start_time\n",
    "                    self._start_time = current_time\n",
    "\n",
    "                    loss_value = run_values.results\n",
    "                    examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "                    sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "                    format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                                'sec/batch)')\n",
    "                    print (format_str % (datetime.now(), self._step, loss_value,\n",
    "                                   examples_per_sec, sec_per_batch))\n",
    "\n",
    "    with tf.train.MonitoredTrainingSession(\n",
    "        checkpoint_dir=FLAGS.train_dir,\n",
    "        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "               tf.train.NanTensorHook(loss),\n",
    "               _LoggerHook()],\n",
    "        config=tf.ConfigProto(\n",
    "            log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n",
    "        while not mon_sess.should_stop():\n",
    "            mon_sess.run(train_op)\n",
    "\n",
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "    cifar10.maybe_download_and_extract()\n",
    "    if tf.gfile.Exists(FLAGS.train_dir):\n",
    "        tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "    tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "    train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
