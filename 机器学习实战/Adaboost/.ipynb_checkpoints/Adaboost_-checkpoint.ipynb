{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMiNNMiClTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 构建数据和label\n",
    "def loadSimpData():\n",
    "    datMat = np.matrix([[ 1. ,  2.1],\n",
    "        [ 1.5 ,  1.6],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat, classLabels\n",
    "\n",
    "data, label = loadSimpData()\n",
    "data = np.asarray(data)\n",
    "label = np.asarray(label)\n",
    "plt.plot(data[0:2, 0], data[0:2, 1], 'ro')\n",
    "plt.plot(data[2:4, 0], data[2:4, 1], 'kD')\n",
    "plt.plot(data[-1, 0], data[-1, 1], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error:  0.2\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error:  0.2\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error:  0.0\n"
     ]
    }
   ],
   "source": [
    "# 单层决策树，它仅基于单个特征来进行分类，即找到使得误差最小的阈值，可以想如上图无论是从哪个轴去划分，反正你只能砍一刀！！找到使得误差最小的那一刀砍下去！！！\n",
    "# 单层决策树函数\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):#just classify the data\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "\n",
    "\n",
    "def buildStump(dataArr,classLabels,D):\n",
    "    dataMatrix = np.mat(dataArr)\n",
    "    labelMat = np.mat(classLabels).T\n",
    "    m,n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0   # 阈值移动的步数\n",
    "    bestStump = {}   # 用于保存信息，比如：最佳阈值、划分的是哪个特征轴、轴两边哪边是正类\n",
    "    bestClasEst = np.mat(np.zeros((m,1)))\n",
    "    minError = np.inf\n",
    "    for i in range(n):   # 遍历每个轴，因为不确定这个最优的“一刀划分”是在哪个特征轴上\n",
    "        # 求得每个轴的最大最小值，再比上步数得到每一次阈值相隔的步长\n",
    "        rangeMin = dataMatrix[:,i].min()\n",
    "        rangeMax = dataMatrix[:,i].max()\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1,int(numSteps)+1):   # 遍历所有阈值，注意到从-1开始，说明是从数据之外开始的\n",
    "            for inequal in ['lt', 'gt']:   # 对每一个阈值又有两种情况，就是认为阈值两边哪边是正类哪边是负类，lt是少于\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)  # 单层决策树返回样本分类结果\n",
    "                errArr = np.mat(np.ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0   # 因为是计算的错误率，所以将分类正确的置0\n",
    "                weightedError = D.T*errArr  # 文中解释：是基于权重向量的加权求和作为分类器的评价指标的，正常来说应该是基于错误率的，这里可以理解为简化版的衡量标准\n",
    "#                 print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                if weightedError < minError:   # 找出效果最好的分类器\n",
    "                    minError = weightedError   # 误差\n",
    "                    bestClasEst = predictedVals.copy()  # 预测结果\n",
    "                    bestStump['dim'] = i  # 保存特征轴信息\n",
    "                    bestStump['thresh'] = threshVal  # 保存阈值信息\n",
    "                    bestStump['ineq'] = inequal  # 阈值两边的正负类类型\n",
    "    return bestStump,minError,bestClasEst\n",
    "\n",
    "\n",
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):\n",
    "    weakClassArr = []  # 用于保存所有的弱分类器的性能结果信息\n",
    "    m = np.shape(dataArr)[0]   # 返回样本数\n",
    "    D = np.mat(np.ones((m,1))/m)   # 初始权重向量，每个权重都是一样的\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(numIt): # 表示numIt个分类器\n",
    "        bestStump,error,classEst = buildStump(dataArr, classLabels, D)  # 单层决策树分类，返回一个分类器\n",
    "        #print \"D:\",D.T\n",
    "        alpha = float(0.5*np.log((1.0-error)/max(error, 1e-16)))  # 根据上一个弱分类器的误差计算分类器的权重值，分母是为了防止为0的情况\n",
    "        bestStump['alpha'] = alpha  # 保存分类器权重信息\n",
    "        weakClassArr.append(bestStump)   # 保存所有的弱分类器的性能结果信息\n",
    "        #print \"classEst: \",classEst.T\n",
    "        # 更新样本权重向量D\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T,classEst)\n",
    "        D = np.multiply(D,np.exp(expon))\n",
    "        D = D/D.sum()\n",
    "        # 累加分类器的预测值\n",
    "        aggClassEst += alpha*classEst\n",
    "        print(\"aggClassEst: \",aggClassEst.T)\n",
    "        # 对累加的分类器预测结果应用指示函数再求错误的样本数\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m  # 最终的错误率\n",
    "        print(\"total error: \",errorRate)\n",
    "        # 可以看到上面一边累加预测值一边计算错误率，问题是40个弱分类器还没算完就要同时计算集成的预测结果呢\n",
    "        # 因为不一定集成40个才是最好的，也有可能10个错误率就为0了，所以才有下以的if判断，满足条件时中止循环\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr, aggClassEst\n",
    "\n",
    "data,label = loadSimpData()\n",
    "out1, out2 = adaBoostTrainDS(data, label, numIt=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error:  0.2\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error:  0.2\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error:  0.0\n",
      "3\n",
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n",
      "预测类别为：  [[-1.]]\n"
     ]
    }
   ],
   "source": [
    "# 利用训练好的弱分类器以及权重进行测试\n",
    "# 第一个参数为待测数据，第二为训练好的弱分类器\n",
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = np.mat(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        # 弱分类器进行预测\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\n",
    "                                 classifierArr[i]['thresh'],\n",
    "                                 classifierArr[i]['ineq'])#call stump classify\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        print(aggClassEst)\n",
    "    # 对预测值累加和应用指示函数即得到预测类别\n",
    "    return np.sign(aggClassEst)\n",
    "\n",
    "data,label = loadSimpData()\n",
    "weak_clas, out2 = adaBoostTrainDS(data, label, numIt=40)\n",
    "print(len(weak_clas))\n",
    "class_ = adaClassify([0, 0], weak_clas)\n",
    "print(\"预测类别为： \", class_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "书本中还比较了adaboost方法和逻辑回归在马疝病数据集上的性能，结果表明adaboost方法仅采用了50个弱分类器就得到了优于逻辑回归的预测性能，文中还介绍了一般来说集成方法会逐渐达到一个稳定值，不会随着弱分类器数量的增加而增加，后面还介绍了正确率、召回率、ROC曲线等."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
