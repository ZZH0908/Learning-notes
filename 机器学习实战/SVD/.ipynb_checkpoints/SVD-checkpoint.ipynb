{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "奇异值： [9.72140007e+00 5.29397912e+00 6.84226362e-01 1.50962387e-15\n",
      " 1.15387192e-31]\n",
      "---------------------------------------------------------------------------------------\n",
      "重构数据： [[ 1.00000000e+00  1.00000000e+00  1.00000000e+00 -2.84366098e-16\n",
      "  -2.94015497e-16]\n",
      " [ 2.00000000e+00  2.00000000e+00  2.00000000e+00  4.47489534e-16\n",
      "   4.28190736e-16]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00  3.09573758e-16\n",
      "   2.99924358e-16]\n",
      " [ 5.00000000e+00  5.00000000e+00  5.00000000e+00 -1.47703573e-16\n",
      "  -1.95842150e-16]\n",
      " [ 1.00000000e+00  1.00000000e+00 -5.70229711e-16  2.00000000e+00\n",
      "   2.00000000e+00]\n",
      " [-7.49390630e-17  9.96896569e-16 -1.34350906e-15  3.00000000e+00\n",
      "   3.00000000e+00]\n",
      " [-8.18314124e-17  2.75447132e-16 -3.13743829e-16  1.00000000e+00\n",
      "   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def loadExData():\n",
    "    return [[1, 1, 1, 0, 0],\n",
    "            [2, 2, 2, 0, 0],\n",
    "            [1, 1, 1, 0, 0],\n",
    "            [5, 5, 5, 0, 0],\n",
    "            [1, 1, 0, 2, 2],\n",
    "            [0, 0, 0, 3, 3],\n",
    "            [0, 0, 0, 1, 1]]\n",
    "\n",
    "data = loadExData()\n",
    "u, sigma, vt = np.linalg.svd(data)\n",
    "print(\"奇异值：\", sigma)\n",
    "# 重构数据\n",
    "data_ = u[:, :3]*np.mat([[sigma[0], 0, 0], [0, sigma[1], 0], [0, 0, sigma[2]]])*vt[:3, :]\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(\"重构数据：\",data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三种相似度度量方法\n",
    "# 欧式距离\n",
    "def ecludSim(inA,inB):\n",
    "    return 1.0/(1.0 + np.linalg.norm(inA - inB))   # 距离越大相似度越小，距离为0时相似度最大，为1\n",
    "\n",
    "\n",
    "# 皮尔逊相关系数，也就是概率论书本讲到的那个相关系数\n",
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 : return 1.0\n",
    "    return 0.5+0.5*np.corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "\n",
    "# 余弦相似度计算\n",
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T*inB)\n",
    "    denom = np.linalg.norm(inA)*np.linalg.norm(inB)\n",
    "    return 0.5+0.5*(num/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 and 0 similarity is: 1.000000\n",
      "the 1 and 3 similarity is: 0.928746\n",
      "the 1 and 4 similarity is: 1.000000\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "the 2 and 3 similarity is: 1.000000\n",
      "the 2 and 4 similarity is: 0.000000\n",
      "[(2, 2.5), (1, 2.0243290220056256)]\n"
     ]
    }
   ],
   "source": [
    "# 餐馆菜肴推荐引擎、推荐未尝过的菜肴\n",
    "# ###############################################################\n",
    "def loadExData():\n",
    "    return [[4, 4, 0, 2, 2],\n",
    "            [4, 0, 0, 3, 3],\n",
    "            [4, 0, 0, 1, 1],\n",
    "            [1, 1, 1, 2, 0],\n",
    "            [2, 2, 2, 0, 0],\n",
    "            [1, 1, 1, 0, 0],\n",
    "            [5, 5, 5, 0, 0]]\n",
    "\n",
    "# 计算用户对物品的评分值估计\n",
    "def standEst(dataMat, user, simMeas, item):\n",
    "    n = np.shape(dataMat)[1]  # 列，基于物品的\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    for j in range(n):  # 遍历每个菜肴\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0:  # 没尝过的忽略，不用计算\n",
    "            continue\n",
    "        # 返回均吃过两个不同菜肴的用户评分索引\n",
    "        overLap = np.nonzero(np.logical_and(dataMat[:, item].A>0,\n",
    "                                      dataMat[:, j].A>0))[0]\n",
    "        if len(overLap) == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            # 计算菜肴评分相似度作为给定用户对未尝过菜肴的估计评分值\n",
    "            similarity = simMeas(dataMat[overLap,item],\n",
    "                                   dataMat[overLap,j])\n",
    "        print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal  # 使得估计值分数规范化到0-5\n",
    "\n",
    "# # 基于SVD的评分估计\n",
    "# def standEst_(dataMat, user, simMeas, item):\n",
    "#     n = np.shape(dataMat)[1]  # 列，基于物品的\n",
    "#     simTotal = 0.0; ratSimTotal = 0.0\n",
    "#     u, sigma, vt = np.linalg.svd(data)\n",
    "#     sig3 = np.eye(3)*sigma[:3]\n",
    "#     data_ = u[:, :3]*sig3*vt[:3, :]\n",
    "#     for j in range(n):  # 遍历每个菜肴\n",
    "#         userRating = dataMat[user,j]\n",
    "#         if userRating == 0:  # 没尝过的忽略，不用计算\n",
    "#             continue\n",
    "#         # 返回均吃过两个不同菜肴的用户评分索引\n",
    "#         overLap = np.nonzero(np.logical_and(data_[:, item].A>0,\n",
    "#                                       data_[:, j].A>0))[0]\n",
    "#         if len(overLap) == 0:\n",
    "#             similarity = 0\n",
    "#         else:\n",
    "#             # 用菜肴评分相似度来计算给定用户对未尝过菜肴的估计评分值\n",
    "#             similarity = simMeas(dataMat[overLap,item],\n",
    "#                                    dataMat[overLap,j])\n",
    "#         print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "#         simTotal += similarity\n",
    "#         ratSimTotal += similarity * userRating  # 还考虑相似度和当前用户评分的乘积\n",
    "#     if simTotal == 0: return 0\n",
    "#     else: return ratSimTotal/simTotal  # 使得估计值分数规范化到0-5\n",
    "\n",
    "\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    \"\"\"\"\"\n",
    "    Parameters:\n",
    "          dataMat: 数据\n",
    "          user: 给定用户  \n",
    "          N: 取最高的前几个推荐结果\n",
    "          simMeas: 相似度度量方法\n",
    "          estMethod: 评分值估计函数方法\n",
    "    Returns:\n",
    "        一个list，保存有最高的前几个推荐结果\n",
    "    \"\"\"\"\"\n",
    "    unratedItems = np.nonzero(dataMat[user,:].A==0)[1]  # 返回未尝过菜肴的索引\n",
    "    # 若全部品尝过则函数结束，所谓推荐肯定是没尝过的~~\n",
    "    if len(unratedItems) == 0:\n",
    "        return 'you rated everything'\n",
    "    itemScores = []  # 用于保存结果\n",
    "    for item in unratedItems:  # 遍历没吃过的菜肴\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)  # 计算菜肴估计值\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]\n",
    "\n",
    "\n",
    "data = loadExData()\n",
    "data = np.mat(data)\n",
    "out = recommend(data, 2)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 构建推荐引擎所面临的挑战：\n",
    "##### 效率问题：\n",
    "1、不需要每次运行程序都要计算一次SVD\n",
    "2、数据中大部分为0，可以通过非零元素来节省内存和计算开销\n",
    "3、各个物品的相似度值可以计算保存起来重复使用\n",
    "##### 冷启动问题：\n",
    "如何在缺乏数据的情况下更好的推荐，也就是说，在协同过滤杨景下，由于新物品到来时由于缺乏所有用户对其的喜好信息，因此无法判断每个用户对其的喜好。而无法判断某个用户对其的喜好，也就无法利用该商品.解决办法：将推荐看成是搜索问题，对物品进行扩展，通过各种标签来描述物品，比如价格贵，荤菜等，这样即使没用用户对某个物品进行评价，也能找到共通的信息."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****original matrix******\n",
      "00000000000000110000000000000000\n",
      "00000000000011111100000000000000\n",
      "00000000000111111110000000000000\n",
      "00000000001111111111000000000000\n",
      "00000000111111111111100000000000\n",
      "00000001111111111111110000000000\n",
      "00000000111111111111111000000000\n",
      "00000000111111100001111100000000\n",
      "00000001111111000001111100000000\n",
      "00000011111100000000111100000000\n",
      "00000011111100000000111110000000\n",
      "00000011111100000000011110000000\n",
      "00000011111100000000011110000000\n",
      "00000001111110000000001111000000\n",
      "00000011111110000000001111000000\n",
      "00000011111100000000001111000000\n",
      "00000001111100000000001111000000\n",
      "00000011111100000000001111000000\n",
      "00000001111100000000001111000000\n",
      "00000001111100000000011111000000\n",
      "00000000111110000000001111100000\n",
      "00000000111110000000001111100000\n",
      "00000000111110000000001111100000\n",
      "00000000111110000000011111000000\n",
      "00000000111110000000111111000000\n",
      "00000000111111000001111110000000\n",
      "00000000011111111111111110000000\n",
      "00000000001111111111111110000000\n",
      "00000000001111111111111110000000\n",
      "00000000000111111111111000000000\n",
      "00000000000011111111110000000000\n",
      "00000000000000111111000000000000\n",
      "****reconstructed matrix using 2 singular values******\n",
      "00000000000000000000000000000000\n",
      "00000000000000000000000000000000\n",
      "00000000000001111100000000000000\n",
      "00000000000011111111000000000000\n",
      "00000000000111111111100000000000\n",
      "00000000001111111111110000000000\n",
      "00000000001111111111110000000000\n",
      "00000000011110000000001000000000\n",
      "00000000111100000000001100000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001110000000\n",
      "00000000111100000000001100000000\n",
      "00000000001111111111111000000000\n",
      "00000000001111111111110000000000\n",
      "00000000001111111111110000000000\n",
      "00000000000011111111100000000000\n",
      "00000000000011111111000000000000\n",
      "00000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# 基于SVD的图像压缩\n",
    "def printMat(inMat, thresh=0.8):\n",
    "    for i in range(32):\n",
    "        for k in range(32):\n",
    "            if float(inMat[i,k]) > thresh:\n",
    "                print(1, end=\"\")\n",
    "            else: print(0, end=\"\")\n",
    "        print('')\n",
    "\n",
    "def imgCompress(numSV=2, thresh=0.8):\n",
    "    myl = []\n",
    "    for line in open('0_5.txt').readlines():\n",
    "        newRow = []\n",
    "        for i in range(32):\n",
    "            newRow.append(int(line[i]))\n",
    "        myl.append(newRow)\n",
    "    myMat = np.mat(myl)\n",
    "    print(\"****original matrix******\")\n",
    "    printMat(myMat, thresh)\n",
    "    U,Sigma,VT = np.linalg.svd(myMat) #奇异值分解\n",
    "    SigRecon = np.mat(np.zeros((numSV, numSV)))\n",
    "    for k in range(numSV):#construct diagonal matrix from vector\n",
    "        SigRecon[k,k] = Sigma[k]\n",
    "    reconMat = U[:,:numSV]*SigRecon*VT[:numSV,:] #重构,只要numSV维\n",
    "    print(\"****reconstructed matrix using %d singular values******\" % numSV)\n",
    "    printMat(reconMat, thresh)\n",
    "\n",
    "imgCompress() \n",
    "# 仅仅用两个奇异值就可以精确的重构数据，但所需要的矩阵元素信息只有原来的十分之一，64+64+2/32*32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
